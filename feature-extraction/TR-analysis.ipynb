{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "folder = '../journal-full-text'\n",
    "# List all files in the folder with csv\n",
    "journals = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "journal_issn_list = [['TRA','0965-8564'],\n",
    "                     ['TRB','0191-2615'],\n",
    "                     ['TRC','0968-090X'],\n",
    "                     ['TRD','1361-9209'],\n",
    "                     ['TRE','1366-5545'],\n",
    "                     ['TRF','1369-8478'],\n",
    "                     ['TRIP','2590-1982']]\n",
    "journal_issn_df = pd.DataFrame(journal_issn_list, columns=['journal','issn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIP:3.04%\n",
      "TRA:3.67%\n",
      "TRB:10.05%\n",
      "TRE:3.40%\n",
      "TRF:1.43%\n",
      "TRC:12.49%\n",
      "TRD:3.35%\n"
     ]
    }
   ],
   "source": [
    "for journal in journals:\n",
    "    # get the journal without the .csv\n",
    "    journal_issn = journal.split('.csv')[0]\n",
    "    journal_folder = os.path.join(folder, journal_issn)\n",
    "    files = os.listdir(journal_folder)\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        # filter the file with .txt\n",
    "        if file.endswith('.txt'):\n",
    "            # read the file\n",
    "            with open(journal_folder + '/' + file, 'r') as f:\n",
    "                text = f.read()\n",
    "                if 'github.com' in text:\n",
    "                    count += 1\n",
    "    journal_name = journal_issn_df[journal_issn_df['issn'] == journal_issn]['journal'].values[0]\n",
    "    print(f\"{journal_name}:{(count/len(files) * 100):.2f}%\")\n",
    "    # print the journal name in match with the issn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of llama for the code and data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 6: Numerical experiments\n",
      "Text: This section reports on the results of the experiments conducted to show the effectiveness and efficiency of the Lagrangian relaxation-based method. The solution algorithm is implemented in C using the CPLEX of version 12.6. Experiments are performed on an Intel Xeon (2.1 GHz) Desktop PC with 16 GB RAM. In  We generate the test data based on practical conditions of the Pearl River Delta (PRD) of China \n",
      "                         \n",
      "                         \n",
      "                         Consider a planning period of 5 hours (i.e.,  \n",
      "                         For the Lagrangian relaxation-based method proposed in  \n",
      "                         \n",
      "                         \n",
      "                         We next examine the convergence of the Lagrangian relaxation-based method for solving the large instances having 80 and 100 vessels.  To prove computationally that the proposed Lagrangian relaxation-based method is of practical interest in producing quick and good solutions, we further examine its performance on finding lower bound solutions in a small number of iterations.  As shown in  Results in  In the DSP, many input parameters are assumed to be known in advance. Sensitivity analysis on some parameters, such as the endurance of a drone’s battery  As mentioned earlier, a bottleneck in the use of drones for monitoring vessels in the ECA is induced by the limit of battery’s endurance. In general, using durable drones can cover more vessels for the inspection, i.e., a vessel that is originally too far to inspect can now be included in a longer scheduled tour.  \n",
      "                         We also conduct sensitivity tests for the solutions based on different numbers of deployed drones.  \n",
      "                         A case study based on realistic vessel location data is provided to examine the DSP solution. We capture the location data of 20 vessels sailing inside the PRD zone from the automatic identification system, with the time between 7am and 5pm on the day of April 23, 2018. The real-time location of each vessel is collected every 3 minutes. The time period is discretized by 200 time units.  Based on the realistic data, we consider three scenarios to test the DSP solutions. The first is a base scenario considering a single drone base station near HK, whose (long, lat) coordinates are given as (114.2, 22.2), and two drones are deployed. The second scenario is extended from the base scenario, in which we enforce that each scheduled tour of drone has only one vessel to inspect. Solution of this scenario can be obtained by running our algorithm based on a modified time-expanded network, where all arcs between vessel-time nodes are removed. In the third scenario, we include an additional base station near CW, with its (long, lat) coordinates fixed as (113.9, 22.5). No extra drones are initially assigned to CW. In all scenarios, suppose each drone can fly at a maximum speed of 50 knots. Drone’s endurance time is set to 180 minutes (i.e., 60 time units). The time for battery replacement and for inspecting each vessel’s emission are both set to 6 minutes (i.e., 2 time units). To keep safety, only one takeoff or landing operation is allowed within each unit time gap. The flying distance between any two locations is computed based on the longitude-latitude system. \n",
      "                         Based on Scenario-3, we next look into how the initial allocation of drones to base stations influences the solution, when the total number of used drones are fixed. Suppose three drones are allocated to HK and CW, thus generating four different allocation combinations, i.e., (HK:3,CW:0), (HK:2,CW:1), (HK:1,CW:2), and (HK:0,CW:3). For the first two cases, where no less than two drones are allocated to the station of HK, the 20 vessels are all inspected in both solutions, obtaining the total weighted vessel number as 200. For the solution of (HK:1,CW:2), vessel 10 will not be covered for inspection, and the obtained weighted vessel number is reduced to 193. When all the three drones are allocated to the station of CW at the beginning, neither vessel 10 or vessel 16 is included in any inspection tour, resulting in the solution objective further reduced to 181. It is hence seen that the initial allocation of drones can be an active factor to influence the solution effectiveness. This fact motivates experienced practitioners to reposition drones during non-operating hours, so as to increase the number of inspected vessels. In the model, real-time locations of vessels are estimated based on their sailing courses and these estimations are assumed to be accurate over the planning horizon. In practice, the estimated paths may deviate from the actual paths during the planning horizon if vessels do not strictly follow their preset courses. Consequently, the solution derived from our model using the estimated vessel locations shall be revalidated for the actual realized locations. In this subsection, we examine the robustness of our method in response to the uncertainty of vessels’ actual paths. The experiments are based on the practical dataset used in  The deviation of estimating vessels’ actual locations is realized as follows: (i)  The central location of the squared area is denoted by ( We perform the experiments following the Scenario-1 setting defined in  As shown in \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_sections_and_text_from_xml(file_path):\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Namespace to handle XML namespaces\n",
    "    namespaces = {\n",
    "        'xocs': 'http://www.elsevier.com/xml/xocs/dtd',\n",
    "        'ce': 'http://www.elsevier.com/xml/common/dtd',\n",
    "        'ja': 'http://www.elsevier.com/xml/ja/dtd'\n",
    "    }\n",
    "\n",
    "    # Extracting the sections using the item-toc element\n",
    "    sections = []\n",
    "    for item in root.findall('.//xocs:item-toc-entry', namespaces):\n",
    "        section_title = item.find('xocs:item-toc-section-title', namespaces)\n",
    "        section_label = item.find('xocs:item-toc-label', namespaces)\n",
    "        section_text = []\n",
    "        \n",
    "        # Use the section label to find the corresponding section id in <ce:section>\n",
    "        if section_label is not None:\n",
    "            label_text = section_label.text.strip()\n",
    "            section_elem = root.find(f\".//ce:section[ce:label='{label_text}']\", namespaces)\n",
    "            if section_elem is not None:\n",
    "                section_id = section_elem.get('id')\n",
    "                if section_id:\n",
    "                    # Now use the section id to extract paragraphs\n",
    "                    paragraphs = section_elem.findall('.//ce:para', namespaces=namespaces)\n",
    "                    section_text = ' '.join([para.text for para in paragraphs if para is not None])  # Get all paragraph texts for the specific section\n",
    "        \n",
    "        if section_title is not None and section_label is not None:\n",
    "            sections.append({\n",
    "                \"label\": section_label.text,\n",
    "                \"title\": section_title.text,\n",
    "                \"text\": section_text\n",
    "            })\n",
    "\n",
    "    return sections\n",
    "\n",
    "# Example usage\n",
    "file_path = '../10.1016_j.trb.2018.10.011.xml'\n",
    "sections = extract_sections_and_text_from_xml(file_path)\n",
    "for section in sections:\n",
    "    if 'experiment' in section['title']:\n",
    "        print(f\"Section {section['label']}: {section['title']}\")\n",
    "        print(f\"Text: {section['text']}\")\n",
    "        sectiontext = section['text']\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPLEX\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": sectiontext + \"Which programing language the algorithm is deployed? Only with the name.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the data mentioned in this text does not appear to be publicly accessible. The text mentions that the location data of 20 vessels sailing inside the PRD zone is captured from an automatic identification system (AIS), but it does not provide information on how to access this data or where it was originally obtained.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": sectiontext + \"Is the data mentioned here publicly accessible? Can I get the data? Answer with Yes or No.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sankey diagram toy example for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Define nodes (categories)\n",
    "nodes = dict(\n",
    "    label=[\"Input\", \"Output 1\", \"Output 2\", \"Output 3\", \"Another Input\", \"Output A\", \"Output B\"],  # Labels for nodes\n",
    "    pad=20,       # Padding between nodes\n",
    "    thickness=20, # Thickness of nodes\n",
    "    color=[\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"yellow\", \"cyan\"]  # Colors for nodes\n",
    ")\n",
    "\n",
    "# Define links (flows between nodes)\n",
    "links = dict(\n",
    "    source=[0, 0, 0, 0, 4, 4],  # Indices of source nodes\n",
    "    target=[1, 2, 3, 4, 5, 6],  # Indices of target nodes\n",
    "    value=[100, 30, 20, 50, 15, 35],  # Values of the flows\n",
    "    color=[\"blue\", \"orange\", \"green\", \"red\", \"purple\", \"yellow\"]  # Colors for links (optional)\n",
    ")\n",
    "\n",
    "# Create the Sankey diagram\n",
    "fig = go.Figure(go.Sankey(\n",
    "    node=nodes,\n",
    "    link=links\n",
    "))\n",
    "\n",
    "# Add a title and show the figure\n",
    "fig.update_layout(title_text=\"Sankey Diagram Example\", font_size=14)\n",
    "fig.write_html(\"../sankey_diagram.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RR-measure",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
